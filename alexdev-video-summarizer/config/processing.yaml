# alexdev-video-summarizer Configuration
# Scene-based institutional knowledge extraction settings

# Application Settings
app:
  name: "alexdev-video-summarizer"
  version: "1.0.0"
  description: "Scene-based institutional knowledge extraction"

# Directory Configuration
paths:
  input_dir: "input"
  output_dir: "output" 
  build_dir: "build"
  models_dir: "models"
  logs_dir: "logs"
  temp_dir: "temp"

# FFmpeg Settings
ffmpeg:
  # Audio extraction settings (optimized for Whisper)
  audio:
    sample_rate: 22050
    bit_depth: 16
    channels: 2
    format: "wav"
    codec: "pcm_s16le"
  
  # Video extraction settings  
  video:
    codec: "libx264"
    quality: "high"
    preserve_resolution: true
    preserve_framerate: true
    
  # Hardware acceleration (auto-detect)
  hardware_accel: "auto"
  thread_count: "auto"

# Scene Detection Settings
scene_detection:
  # PySceneDetect configuration
  threshold: 27.0              # Content change threshold
  min_scene_length: 2.0        # Minimum scene duration (seconds)
  downscale_factor: 1          # 1 = full resolution analysis
  frame_skip: 0                # Analyze every frame for accuracy
  
  # Fallback settings
  fallback_to_time_based: true
  time_based_scene_length: 120  # 2-minute fallback scenes

# GPU Pipeline Configuration  
gpu_pipeline:
  # Sequential processing to prevent CUDA conflicts
  sequential_processing: true
  memory_cleanup: true
  max_gpu_memory_usage: 0.9    # 90% GPU memory limit
  
  # YOLO Settings
  yolo:
    model: "yolov8n.pt"         # Nano model for speed
    confidence_threshold: 0.5
    device: "auto"              # auto, cuda, cpu
    
  # EasyOCR Settings
  easyocr:
    languages: ["en"]           # English text recognition
    gpu: true
    confidence_threshold: 0.5
    
  # Whisper Settings (Hybrid: Original Whisper GPU + WhisperX features)
  whisper:
    model_size: "large-v2"      # large-v2 for best accuracy
    device: "cuda"              # GPU with original Whisper
    language: "en"              # Force English to prevent translation
    
    # Hybrid mode: Use original Whisper with WhisperX features
    use_original_whisper: true  # Fallback to original Whisper for GPU compatibility
    enable_silero_vad: true     # Add Silero VAD for better segmentation
    
    # VAD Settings (Voice Activity Detection)
    vad_threshold: 0.4          # Silero VAD sensitivity (0.1-0.9)
    chunk_threshold: 3.0        # Split chunks on gaps > 3 seconds (legacy setting)
    
    # Word timestamps (original Whisper supports this)
    enable_word_timestamps: true # Enable word-level timestamps
    enable_word_alignment: true  # Enable WhisperX word alignment when available
    
    # Advanced Chunking for Advertisement Content
    chunking_strategy: "multi_strategy"  # Options: 'gap_based', 'duration_based', 'multi_strategy'
    max_chunk_duration: 20.0    # Maximum chunk duration (seconds) - prevents very long chunks
    min_chunk_duration: 5.0     # Minimum chunk duration (seconds) - merges very short chunks
    energy_based_splitting: true # Enable energy-based splitting at natural breaks
    
    # Sequential model loading for GPU memory management
    sequential_model_loading: true  # Load/unload diarization model separately to manage GPU memory
    
    # Speaker Diarization
    hft_encoded: "bDACrQSIdR1zeISygygiVeZgUfMbTzGh_fh"
    enable_diarization: true    # Enable speaker diarization when token available
    max_speakers: 10            # Maximum number of speakers to detect
    min_speakers: 1             # Minimum number of speakers to detect

# CPU Pipeline Configuration
cpu_pipeline:
  # Parallel processing settings
  max_workers: 3               # Thread pool size
  timeout_seconds: 300         # 5 minute timeout per tool
  
  # OpenCV Settings
  opencv:
    face_detection:
      scale_factor: 1.1
      min_neighbors: 5
      min_size: [30, 30]
      
  # LibROSA Settings  
  librosa:
    sample_rate: 22050
    hop_length: 512
    n_mfcc: 13
    
    # Smart Music Segmentation (detects style changes automatically)
    enable_music_segmentation: true   # Enable music-based analysis segmentation
    adaptive_segmentation: true       # Use smart boundary detection vs fixed-time
    
    # Smart segmentation parameters
    min_segment_length: 3.0          # Minimum segment duration (seconds)
    max_segment_length: 30.0         # Maximum segment duration (seconds)
    
    # Feature change detection thresholds
    spectral_change_threshold: 0.3   # Sensitivity for musical style changes
    tempo_change_threshold: 10.0     # BPM change threshold for rhythm detection
    harmonic_change_threshold: 0.4   # Chord/key change sensitivity
    energy_change_threshold: 0.5     # Volume/dynamics change sensitivity
    
    # Fixed segmentation fallback (when smart detection disabled)
    segment_length: 10.0             # Fixed segment duration (seconds)
    segment_overlap: 2.0             # Overlap between segments (seconds)
    
  # pyAudioAnalysis Settings - UPDATED: Fake interpretive analysis removed
  pyaudioanalysis:
    window_size: 0.050          # 50ms windows
    step_size: 0.025            # 25ms step size
    features: "all"             # Extract all 68 features (numerical only)
    output_mode: "numerical"    # CHANGED: Only numerical - fake interpretive removed
    # REMOVED interpretive mode - was fake heuristic analysis with arbitrary thresholds
    # Timeline services now handle real event-based analysis

# Error Handling & Circuit Breaker
error_handling:
  # Circuit breaker configuration
  circuit_breaker_threshold: 3  # Abort after 3 consecutive failures
  
  # Retry settings
  max_retries: 1
  retry_delay: 5               # seconds
  
  # Error recovery
  continue_on_tool_failure: false  # Fail-fast approach
  cleanup_failed_artifacts: true
  
  # GPU error handling
  gpu_memory_recovery: true
  cuda_cache_cleanup: true

# Performance Settings
performance:
  # Processing targets
  target_processing_time: 600  # 10 minutes per video
  max_processing_time: 1800    # 30 minute timeout
  
  # Memory management
  force_gc_after_video: true
  gpu_memory_cleanup: true
  
  # Progress reporting
  progress_update_interval: 5   # seconds
  detailed_progress: true

# Output Settings
output:
  # Knowledge base format
  format: "markdown"
  scene_by_scene: true
  include_metadata: true
  include_cross_references: true
  
  # File naming
  filename_pattern: "{video_name}.md"
  master_index: "INDEX.md"
  
  # Content options
  include_timestamps: true
  include_confidence_scores: false
  max_scene_description_length: 500

# Logging Configuration
logging:
  level: "INFO"                # DEBUG, INFO, WARNING, ERROR
  file_logging: true
  console_logging: true
  log_format: "detailed"       # simple, detailed
  
  # Log file settings
  max_log_size: "10MB"
  backup_count: 3
  
  # Component logging levels
  services:
    ffmpeg: "INFO"
    scene_detection: "INFO"
    gpu_pipeline: "INFO"
    cpu_pipeline: "INFO"
    knowledge_generator: "INFO"

# Development Settings (for testing)
development:
  mock_ai_services: false      # PRODUCTION: Enable real AI services
  skip_model_loading: false    # PRODUCTION: Load all AI models for real processing
  skip_ffmpeg_check: false     # FFmpeg is now installed and ready
  fast_mode: false             # PRODUCTION: Full quality processing
  debug_artifacts: true        # Keep intermediate files for debugging