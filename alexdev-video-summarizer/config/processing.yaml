# alexdev-video-summarizer Configuration
# Scene-based institutional knowledge extraction settings
# DEMUCS OPTIMIZATION: With clean audio separation, each service focuses only on its expertise

# Application Settings
app:
  name: "alexdev-video-summarizer"
  version: "1.0.0"
  description: "Scene-based institutional knowledge extraction"

# Directory Configuration
paths:
  input_dir: "input"
  output_dir: "output" 
  build_dir: "build"
  models_dir: "models"
  logs_dir: "logs"
  temp_dir: "temp"

# FFmpeg Settings
ffmpeg:
  # Audio extraction settings (optimized for Whisper)
  audio:
    sample_rate: 22050
    bit_depth: 16
    channels: 2
    format: "wav"
    codec: "pcm_s16le"
  
  # Video extraction settings  
  video:
    codec: "libx264"
    quality: "high"
    preserve_resolution: true
    preserve_framerate: true
    
  # Hardware acceleration (auto-detect)
  hardware_accel: "auto"
  thread_count: "auto"

# Scene Detection Settings
scene_detection:
  # PySceneDetect configuration - TUNED FOR 30s/8-scene DETECTION
  threshold: 15.0              # LOWERED: More sensitive for short video transitions  
  min_scene_length: 0.3        # LOWERED: Allow very short scenes (0.3s minimum)
  downscale_factor: 1          # 1 = full resolution analysis for accuracy
  frame_skip: 0                # Analyze every frame for maximum accuracy
  
  # Fallback settings
  fallback_to_time_based: true
  time_based_scene_length: 120  # 2-minute fallback scenes

# GPU Pipeline Configuration  
gpu_pipeline:
  # Sequential processing to prevent CUDA conflicts
  sequential_processing: true
  memory_cleanup: true
  max_gpu_memory_usage: 0.9    # 90% GPU memory limit
  
    
  # InternVL3 VLM Settings - Replaces YOLO+EasyOCR+OpenCV
  # RAPID MODEL TESTING: Change model_name and model_path to test different models
  # Model names will automatically appear in filenames, logs, and metadata
  internvl3:
    model_name: "InternVL3_5-2B"
    model_path: "OpenGVLab/InternVL3_5-2B"
    device: "cuda"
    confidence_threshold: 0.7
    max_tokens: 512
    frame_sample_rate: 3
    
    # Generation Configuration - Controls inference behavior
    generation_config:
      num_beams: 1
      max_new_tokens: 512
      do_sample: false
      temperature: 0.0
      repetition_penalty: 1.0
      max_length: 8192
      top_p: 0.9
    
    # VLM analysis modes
    comprehensive_analysis: true       # Full scene understanding
    text_extraction: true             # Extract all readable text from scenes
    change_detection: true            # Detect changes between scenes
    
    # Additional VLM settings
    max_input_tiles: 6                # Maximum image tiles for dynamic preprocessing
    use_thumbnail: false              # Use thumbnail in multi-tile processing
    
    # Development settings
    mock_responses: false             # Use real VLM (set true for development)
  
    
  # Whisper Settings (Hybrid: Original Whisper GPU + WhisperX features)
  whisper:
    model_size: "large-v2"      # large-v2 for best accuracy
    device: "cuda"              # GPU with original Whisper
    language: "en"              # Force English to prevent translation
    
    # Hybrid mode: Use original Whisper with WhisperX features
    use_original_whisper: true  # Fallback to original Whisper for GPU compatibility
    enable_silero_vad: true     # Add Silero VAD for better segmentation
    
    # VAD Settings (Voice Activity Detection) - Optimized for fast-paced ads
    vad_threshold: 0.3          # Voice activity detection sensitivity
    chunk_threshold: 1.0        # Gap required to split chunks (1s for fast-paced ads)
    
    # Word timestamps (original Whisper supports this)
    enable_word_timestamps: true # Enable word-level timestamps
    enable_word_alignment: true  # Enable WhisperX word alignment when available
    
    # Advanced Chunking for Advertisement Content
    chunking_strategy: "multi_strategy"  # Options: 'gap_based', 'duration_based', 'multi_strategy'
    max_chunk_duration: 20.0    # Maximum chunk duration (seconds) - prevents very long chunks
    min_chunk_duration: 5.0     # Minimum chunk duration (seconds) - merges very short chunks
    energy_based_splitting: true # Enable energy-based splitting at natural breaks
    
    # Sequential model loading for GPU memory management
    sequential_model_loading: true  # Load/unload diarization model separately to manage GPU memory
    
    # Speaker Diarization
    hft_encoded: "bDACrQSIdR1zeISygygiVeZgUfMbTzGh_fh"
    enable_diarization: true    # Enable speaker diarization when token available
    max_speakers: 10            # Maximum number of speakers to detect
    min_speakers: 1             # Minimum number of speakers to detect

# CPU Pipeline Configuration
cpu_pipeline:
  # Parallel processing settings
  max_workers: 3               # Thread pool size
  timeout_seconds: 300         # 5 minute timeout per tool
  
      
  # LibROSA Settings  
  librosa:
    sample_rate: 22050
    hop_length: 512
    n_mfcc: 13
    
    # Smart Music Segmentation (detects style changes automatically)
    enable_music_segmentation: true   # Enable music-based analysis segmentation
    adaptive_segmentation: true       # Use smart boundary detection vs fixed-time
    
    # Smart segmentation parameters
    min_segment_length: 3.0          # Minimum segment duration (seconds)
    max_segment_length: 30.0         # Maximum segment duration (seconds)
    
    # Feature change detection thresholds
    spectral_change_threshold: 0.3   # Sensitivity for musical style changes
    tempo_change_threshold: 10.0     # BPM change threshold for rhythm detection
    harmonic_change_threshold: 0.4   # Chord/key change sensitivity
    energy_change_threshold: 0.5     # Volume/dynamics change sensitivity
    
    # Fixed segmentation fallback (when smart detection disabled)
    segment_length: 10.0             # Fixed segment duration (seconds)
    segment_overlap: 2.0             # Overlap between segments (seconds)
    
  # pyAudioAnalysis Settings - UPDATED: Fake interpretive analysis removed
  pyaudioanalysis:
    window_size: 0.050          # 50ms windows
    step_size: 0.025            # 25ms step size
    features: "all"             # Extract all 68 features (numerical only)
    output_mode: "numerical"    # CHANGED: Only numerical - fake interpretive removed
    # REMOVED interpretive mode - was fake heuristic analysis with arbitrary thresholds
    # Timeline services now handle real event-based analysis

# Enhanced Timeline Merger Settings
timeline_merger:
  # LibROSA Speech Artifact Filtering
  enable_speech_artifact_filtering: true   # Filter LibROSA events that correlate with speech
  
  # PyAudio-based filtering (distance from PyAudio emotion change events)
  pyaudio_distance_threshold: 0.7         # LibROSA events >0.7s from PyAudio events are likely valid musical events
  
  # Boundary exception rules - preserve events near structural boundaries
  boundary_exception_distance: 0.5        # Events within 0.5s of boundaries are preserved regardless of other filters
  preserve_boundary_events: true          # Enable boundary exception logic
  
  # Alternative filtering methods (if PyAudio filtering disabled)
  word_distance_threshold: 0.15           # LibROSA events >0.15s from words (less reliable)
  enable_event_clustering_filter: false   # Filter dense clusters of events (experimental)

# Error Handling & Circuit Breaker
error_handling:
  # Circuit breaker configuration
  circuit_breaker_threshold: 3  # Abort after 3 consecutive failures
  
  # Retry settings
  max_retries: 1
  retry_delay: 5               # seconds
  
  # Error recovery
  continue_on_tool_failure: false  # Fail-fast approach
  cleanup_failed_artifacts: true
  
  # GPU error handling
  gpu_memory_recovery: true
  cuda_cache_cleanup: true

# Performance Settings
performance:
  # Processing targets
  target_processing_time: 600  # 10 minutes per video
  max_processing_time: 1800    # 30 minute timeout
  
  # Memory management
  force_gc_after_video: true
  gpu_memory_cleanup: true
  
  # Progress reporting
  progress_update_interval: 5   # seconds
  detailed_progress: true

# Output Settings
output:
  # Knowledge base format
  format: "markdown"
  scene_by_scene: true
  include_metadata: true
  include_cross_references: true
  
  # File naming
  filename_pattern: "{video_name}.md"
  master_index: "INDEX.md"
  
  # Content options
  include_timestamps: true
  include_confidence_scores: false
  max_scene_description_length: 500

# Logging Configuration
logging:
  level: "INFO"                # DEBUG, INFO, WARNING, ERROR
  file_logging: true
  console_logging: true
  log_format: "detailed"       # simple, detailed
  
  # Log file settings
  max_log_size: "10MB"
  backup_count: 3
  
  # Component logging levels
  services:
    ffmpeg: "INFO"
    scene_detection: "INFO"
    gpu_pipeline: "INFO"
    cpu_pipeline: "INFO"
    knowledge_generator: "INFO"

# DEMUCS OPTIMIZATION: Service-Specific Analysis Focus
audio_optimization:
  # LibROSA on no_vocals.wav - Full music analysis (everything on)
  librosa_music:
    analyze_tempo_changes: true        # Essential for music
    analyze_harmonic_shifts: true      # Essential for music  
    analyze_energy_transitions: true   # Keep - valuable for music dynamics
    analyze_onset_events: true         # Keep - valuable for music analysis
    analyze_structural_segments: true  # Essential for music structure
    
  # PyAudio on vocals.wav - Focus on speech only  
  pyaudio_voice:
    analyze_speaker_changes: true     # Essential for speech
    analyze_emotion_changes: true     # Valuable for voice analysis
    analyze_sound_effects: false     # Skip - no sound effects in clean vocals
    analyze_music_features: false    # Skip - vocals track has no music
    
  # PyAudio on no_vocals.wav - Focus on sound effects, music features, and genre
  pyaudio_music:
    analyze_speaker_changes: false   # Skip - no speakers in music track
    analyze_emotion_changes: false   # Skip - not applicable to music
    analyze_sound_effects: true      # Keep - valuable for institutional knowledge
    analyze_music_features: true     # Essential for music classification
    analyze_genre_classification: true # Valuable for institutional categorization

# Development Settings (for testing)
development:
  mock_ai_services: false      # PRODUCTION: Use real InternVL3 model
  skip_model_loading: false    # PRODUCTION: Load all AI models for real processing
  skip_ffmpeg_check: false     # FFmpeg is now installed and ready
  fast_mode: false             # PRODUCTION: Full quality processing
  debug_artifacts: true        # Keep intermediate files for debugging